{
  "Train": [
    "# Model training\n",
    "# Algo/CNNAE\n",
    "\n",
    "class ConvAutoencoder:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, filters=(32, 64), latentDim=50):\n",
    "        inputShape = (height, width, depth)\n",
    "        chanDim = -1\n",
    "        inputs = Input(shape=inputShape)\n",
    "        x = inputs\n",
    "        for f in filters:\n",
    "            x = Conv2D(f, (3, 3), strides=2, padding='same')(x)\n",
    "            x = LeakyReLU(alpha=0.2)(x)\n",
    "            x = BatchNormalization(axis=chanDim)(x)\n",
    "        volumeSize = K.int_shape(x)\n",
    "        x = Flatten()(x)\n",
    "        latent = Dense(latentDim)(x)\n",
    "        encoder = Model(inputs, latent, name='encoder')\n",
    "        latentInputs = Input(shape=(latentDim,))\n",
    "        x = Dense(np.prod(volumeSize[1:]))(latentInputs)\n",
    "        x = Reshape((volumeSize[1], volumeSize[2], volumeSize[3]))(x)\n",
    "        for f in filters[::-1]:\n",
    "            x = Conv2DTranspose(f, (3, 3), strides=2,padding='same')(x)\n",
    "            x = LeakyReLU(alpha=0.2)(x)\n",
    "            x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = Conv2DTranspose(depth, (3, 3), padding='same')(x)\n",
    "        outputs = Activation('sigmoid')(x)\n",
    "        decoder = Model(latentInputs, outputs, name='decoder')\n",
    "        autoencoder = Model(inputs, decoder(encoder(inputs)), name='autoencoder')\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "        autoencoder.compile(loss='mse', optimizer=optimizer)\n",
    "        return autoencoder\n",
    "\n",
    "\n",
    "CAE = ConvAutoencoder.build(200, 200, 1)\n",
    "\n",
    "def ae_train(obj, x_train, x_valid = None):\n",
    "    start = time.time()\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
    "    obj.fit(x_train,x_train, epochs=50,batch_size = 10, verbose = True, callbacks= [callback])\n",
    "    print(f'model trained in {(time.time()-start)/60} minutes')\n",
    "\n",
    "\n",
    " # Modify x_train with your training data\n",
    "model = ae_train(CAE, x_train)\n",
    "\n",
    "\n",
    "\n"
  ],
  "Valid": [
    "# Validation Prediction\n",
    "# Algo/CNNAE\n",
    "\n",
    "def detect_anomalies_autoencoder(obj, x_valid0, x_valid1):\n",
    "    prediction_valid0CAE = CAE.predict(x_valid0)\n",
    "    prediction_valid1CAE = CAE.predict(x_valid1)\n",
    "    \n",
    "    r_e_valid0CAE = np.sum(np.sum((X_valid0CAE-prediction_valid0CAE) ** 2, axis=1),axis=1)\n",
    "    r_e_valid1CAE = np.sum(np.sum((X_valid1CAE-prediction_valid1CAE) ** 2, axis=1),axis=1)\n",
    "    \n",
    "    re_valid = np.concatenate((r_e_valid0CAE, r_e_valid1CAE))\n",
    "    \n",
    "    threshold_t_CAE = np.quantile(re_valid,0.7)\n",
    "    \n",
    "    decision0CAE = -r_e_valid0CAE + threshold_t_CAE\n",
    "    decision1CAE = -r_e_valid1CAE + threshold_t_CAE\n",
    "    df0CAE = pd.DataFrame(decision0CAE, columns=['v'])\n",
    "    df1CAE = pd.DataFrame(decision1CAE, columns=['v'])\n",
    "    decision1CAE = -r_e_valid1CAE\n",
    "    \n",
    "    # Computing f1 score of majority class\n",
    "    recall = len(df1CAE[df1CAE.v<0])/len(df1CAE)\n",
    "    precision = len(df1CAE[df1CAE.v<0])/(len(df1CAE[df1CAE.v<0])+len(df0CAE[df0CAE.v<0]))\n",
    "    f1 = 2*precision*recall/(precision+recall)\n",
    "    \n",
    "    # Computing f1 score of majority class\n",
    "    recall_maj = len(df0CAE[df0CAE.v>0])/len(df0CAE)\n",
    "    precision_maj = len(df0CAE[df0CAE.v>0])/(len(df1CAE[df1CAE.v>0])+len(df0CAE[df0CAE.v>0]))\n",
    "    f1_maj = 2*precision_maj*recall_maj/(precision_maj+recall_maj)\n",
    "    \n",
    "    df1CAE.describe()\n",
    "    \n",
    "    print(f'Valid scores:')\n",
    "    print(f'minority class F1 score {f1}')\n",
    "    print(f'majority class F1 score {f1_maj}')\n",
    "    print(f'average F1 score {(f1+f1_maj)/2}')\n",
    "    \n",
    "\n",
    " # Modify x_valid with your validation data\n",
    "anomalies_validation = detect_anomalies_autoencoder(CAE, x_valid0, x_valid1)"
  ],
  "Test": [
    "# Prediction\n",
    "# Algo/CNNAE\n",
    "\n",
    "def detect_anomalies_autoencoder(obj, x_test0, x_test1):\n",
    "    prediction_test0CAE = CAE.predict(x_test0)\n",
    "    prediction_test1CAE = CAE.predict(x_test1)\n",
    "    \n",
    "    r_e_test0CAE = np.sum(np.sum((X_test0CAE-prediction_test0CAE) ** 2, axis=1),axis=1)\n",
    "    r_e_test1CAE = np.sum(np.sum((X_test1CAE-prediction_test1CAE) ** 2, axis=1),axis=1)\n",
    "    \n",
    "    re_test = np.concatenate((r_e_test0CAE, r_e_test1CAE))\n",
    "    \n",
    "    threshold_t_CAE = np.quantile(re_test,0.7)\n",
    "    \n",
    "    decision0CAE = -r_e_test0CAE + threshold_t_CAE\n",
    "    decision1CAE = -r_e_test1CAE + threshold_t_CAE\n",
    "    df0CAE = pd.DataFrame(decision0CAE, columns=['v'])\n",
    "    df1CAE = pd.DataFrame(decision1CAE, columns=['v'])\n",
    "    decision1CAE = -r_e_test1CAE\n",
    "    \n",
    "    # Computing f1 score of majority class\n",
    "    recall = len(df1CAE[df1CAE.v<0])/len(df1CAE)\n",
    "    precision = len(df1CAE[df1CAE.v<0])/(len(df1CAE[df1CAE.v<0])+len(df0CAE[df0CAE.v<0]))\n",
    "    f1 = 2*precision*recall/(precision+recall)\n",
    "    \n",
    "    # Computing f1 score of majority class\n",
    "    recall_maj = len(df0CAE[df0CAE.v>0])/len(df0CAE)\n",
    "    precision_maj = len(df0CAE[df0CAE.v>0])/(len(df1CAE[df1CAE.v>0])+len(df0CAE[df0CAE.v>0]))\n",
    "    f1_maj = 2*precision_maj*recall_maj/(precision_maj+recall_maj)\n",
    "    \n",
    "    df1CAE.describe()\n",
    "    \n",
    "    print(f'test scores:')\n",
    "    print(f'minority class F1 score {f1}')\n",
    "    print(f'majority class F1 score {f1_maj}')\n",
    "    print(f'average F1 score {(f1+f1_maj)/2}')\n",
    "    \n",
    "\n",
    " # Modify x_test with your test data\n",
    "anomalies_test = detect_anomalies_autoencoder(CAE, x_test0, x_test1)"
  ],
  "Imports": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Input\n",
    "from keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras import backend as K\n",
    "import librosa\n",
    "import librosa.display\n",
    "import time\n",
    "import pandas as pd\n"
  ]
}
